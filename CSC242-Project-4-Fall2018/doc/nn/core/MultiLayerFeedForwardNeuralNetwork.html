<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_92) on Tue Nov 13 14:34:03 EST 2018 -->
<title>MultiLayerFeedForwardNeuralNetwork</title>
<meta name="date" content="2018-11-13">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="MultiLayerFeedForwardNeuralNetwork";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../nn/core/LogisticUnit.html" title="class in nn.core"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../nn/core/NeuralNetwork.html" title="class in nn.core"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?nn/core/MultiLayerFeedForwardNeuralNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerFeedForwardNeuralNetwork.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.classes.inherited.from.class.nn.core.NeuralNetwork">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">nn.core</div>
<h2 title="Class MultiLayerFeedForwardNeuralNetwork" class="title">Class MultiLayerFeedForwardNeuralNetwork</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li><a href="../../nn/core/NeuralNetwork.html" title="class in nn.core">nn.core.NeuralNetwork</a></li>
<li>
<ul class="inheritance">
<li><a href="../../nn/core/FeedForwardNeuralNetwork.html" title="class in nn.core">nn.core.FeedForwardNeuralNetwork</a></li>
<li>
<ul class="inheritance">
<li>nn.core.MultiLayerFeedForwardNeuralNetwork</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../nn/examples/IrisNN.html" title="class in nn.examples">IrisNN</a>, <a href="../../nn/examples/MNISTNN.html" title="class in nn.examples">MNISTNN</a></dd>
</dl>
<hr>
<br>
<pre>public abstract class <span class="typeNameLabel">MultiLayerFeedForwardNeuralNetwork</span>
extends <a href="../../nn/core/FeedForwardNeuralNetwork.html" title="class in nn.core">FeedForwardNeuralNetwork</a></pre>
<div class="block">A MultiLayerFeedForwardNeuralNetwork is a FeedForwardNeuralNetwork with at
 least one ``hidden'' layer of units between the inputs and the outputs
 (AIMA Section 18.7.3).</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.nn.core.NeuralNetwork">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from class&nbsp;nn.core.<a href="../../nn/core/NeuralNetwork.html" title="class in nn.core">NeuralNetwork</a></h3>
<code><a href="../../nn/core/NeuralNetwork.Tester.html" title="interface in nn.core">NeuralNetwork.Tester</a>, <a href="../../nn/core/NeuralNetwork.Trainer.html" title="interface in nn.core">NeuralNetwork.Trainer</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.Random</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#random">random</a></span></code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="fields.inherited.from.class.nn.core.FeedForwardNeuralNetwork">
<!--   -->
</a>
<h3>Fields inherited from class&nbsp;nn.core.<a href="../../nn/core/FeedForwardNeuralNetwork.html" title="class in nn.core">FeedForwardNeuralNetwork</a></h3>
<code><a href="../../nn/core/FeedForwardNeuralNetwork.html#layers">layers</a></code></li>
</ul>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#MultiLayerFeedForwardNeuralNetwork-int-int:A-int-">MultiLayerFeedForwardNeuralNetwork</a></span>(int&nbsp;ninputs,
                                  int[]&nbsp;nhiddens,
                                  int&nbsp;noutputs)</code>
<div class="block">Construct and return a new MultiLayerFeedForwardNeuralNetwork with the given
 number of input units, hidden units (array of lengths, one for each layer),
 and the given number of output units, where each layer is fully connected to the next.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#MultiLayerFeedForwardNeuralNetwork-int-int-int-">MultiLayerFeedForwardNeuralNetwork</a></span>(int&nbsp;ninputs,
                                  int&nbsp;nhiddens,
                                  int&nbsp;noutputs)</code>
<div class="block">Construct and return a new MultiLayerFeedForwardNeuralNetwork with the given
 number of input units, a single hidden layer of the given length,
 and the given number of output units, where each layer is fully connected to the next.</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#MultiLayerFeedForwardNeuralNetwork-nn.core.Unit:A:A-">MultiLayerFeedForwardNeuralNetwork</a></span>(<a href="../../nn/core/Unit.html" title="class in nn.core">Unit</a>[][]&nbsp;layers)</code>
<div class="block">Construct and return a new MultiLayerFeedForwardNeuralNetwork with the given
 layers of Units (InputUnits in the first layer, LogisticUnits in other layers).</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#backprop-nn.core.Example-double-">backprop</a></span>(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example,
        double&nbsp;alpha)</code>
<div class="block">AIMA Fig 18.14 body of loop after propagating inputs forward:
 (2) Computing the error vector delta
 (3) ``Propagating deltas backward from output layer to input layer''
 (4) ``Update every weight in network using deltas''</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#dump--">dump</a></span>()</code>
<div class="block">Print this MultiLayerFeedForwardNeuralNetwork to stdout.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#getOutputValue--">getOutputValue</a></span>()</code>
<div class="block">Output of a MultiLayerFeedForwardNeuralNetwork is the index of output unit
 (i.e., class label) with the maximum activation.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#initializeWeights--">initializeWeights</a></span>()</code>
<div class="block">AIMA Fig 18.24 says weights should each be initialized to
 ``a small random number.'' WTF? It also has that step inside
 the learning loop, which strikes me as very wrong.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#kFoldCrossValidate-java.util.List-int-int-double-">kFoldCrossValidate</a></span>(java.util.List&lt;<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&gt;&nbsp;examples,
                  int&nbsp;k,
                  int&nbsp;epochs,
                  double&nbsp;alpha)</code>
<div class="block">Run a k-fold cross-validation experiment on this MultiLayerFeedForwardNeuralNetwork using
 the given Examples and return the average accuracy over the k trials.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#propagate-nn.core.Example-">propagate</a></span>(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example)</code>
<div class="block">AIMA Fig 18.14: Body of main loop, step 1:
 ``Propagate the inputs forward to compute the outputs.''</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#test-nn.core.Example-">test</a></span>(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example)</code>
<div class="block">Return true if this MultiLayerFeedForwardNeuralNetwork gets the right answer
 on the given Example.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#train-nn.core.Example-double-">train</a></span>(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example,
     double&nbsp;alpha)</code>
<div class="block">AIMA Fig 18.14 body of loop looks like three steps, but it's really four:
 (1) ``Propagate the inputs forward to compute the outputs''
 (2) Computing the error vector delta
 (3) ``Propagating deltas backward from output layer to input layer''
 (4) ``Update every weight in network using deltas''</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../nn/core/MultiLayerFeedForwardNeuralNetwork.html#train-java.util.List-int-double-">train</a></span>(java.util.List&lt;<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&gt;&nbsp;examples,
     int&nbsp;epochs,
     double&nbsp;alpha)</code>
<div class="block">AIMA BACK-PROP-LEARNING algorithm (Fig 18.24).</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.nn.core.FeedForwardNeuralNetwork">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;nn.core.<a href="../../nn/core/FeedForwardNeuralNetwork.html" title="class in nn.core">FeedForwardNeuralNetwork</a></h3>
<code><a href="../../nn/core/FeedForwardNeuralNetwork.html#getInputUnits--">getInputUnits</a>, <a href="../../nn/core/FeedForwardNeuralNetwork.html#getLayerUnits-int-">getLayerUnits</a>, <a href="../../nn/core/FeedForwardNeuralNetwork.html#getNumLayers--">getNumLayers</a>, <a href="../../nn/core/FeedForwardNeuralNetwork.html#getOutputUnits--">getOutputUnits</a>, <a href="../../nn/core/FeedForwardNeuralNetwork.html#getOutputValues--">getOutputValues</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.nn.core.NeuralNetwork">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;nn.core.<a href="../../nn/core/NeuralNetwork.html" title="class in nn.core">NeuralNetwork</a></h3>
<code><a href="../../nn/core/NeuralNetwork.html#addListener-nn.core.NeuralNetworkListener-">addListener</a>, <a href="../../nn/core/NeuralNetwork.html#kFoldCrossValidate-java.util.List-int-nn.core.NeuralNetwork.Trainer-nn.core.NeuralNetwork.Tester-">kFoldCrossValidate</a>, <a href="../../nn/core/NeuralNetwork.html#notifyTrainingEpochCompleted-int-">notifyTrainingEpochCompleted</a>, <a href="../../nn/core/NeuralNetwork.html#notifyTrainingEpochStarted-int-">notifyTrainingEpochStarted</a>, <a href="../../nn/core/NeuralNetwork.html#removeListener-nn.core.NeuralNetworkListener-">removeListener</a>, <a href="../../nn/core/NeuralNetwork.html#test-java.util.List-">test</a></code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="random">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>random</h4>
<pre>protected&nbsp;java.util.Random random</pre>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="MultiLayerFeedForwardNeuralNetwork-nn.core.Unit:A:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerFeedForwardNeuralNetwork</h4>
<pre>public&nbsp;MultiLayerFeedForwardNeuralNetwork(<a href="../../nn/core/Unit.html" title="class in nn.core">Unit</a>[][]&nbsp;layers)</pre>
<div class="block">Construct and return a new MultiLayerFeedForwardNeuralNetwork with the given
 layers of Units (InputUnits in the first layer, LogisticUnits in other layers).
 It's up to you to arrange the feed-forward connections between the Units
 properly.</div>
</li>
</ul>
<a name="MultiLayerFeedForwardNeuralNetwork-int-int:A-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerFeedForwardNeuralNetwork</h4>
<pre>public&nbsp;MultiLayerFeedForwardNeuralNetwork(int&nbsp;ninputs,
                                          int[]&nbsp;nhiddens,
                                          int&nbsp;noutputs)</pre>
<div class="block">Construct and return a new MultiLayerFeedForwardNeuralNetwork with the given
 number of input units, hidden units (array of lengths, one for each layer),
 and the given number of output units, where each layer is fully connected to the next.</div>
</li>
</ul>
<a name="MultiLayerFeedForwardNeuralNetwork-int-int-int-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>MultiLayerFeedForwardNeuralNetwork</h4>
<pre>public&nbsp;MultiLayerFeedForwardNeuralNetwork(int&nbsp;ninputs,
                                          int&nbsp;nhiddens,
                                          int&nbsp;noutputs)</pre>
<div class="block">Construct and return a new MultiLayerFeedForwardNeuralNetwork with the given
 number of input units, a single hidden layer of the given length,
 and the given number of output units, where each layer is fully connected to the next.</div>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="dump--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dump</h4>
<pre>public&nbsp;void&nbsp;dump()</pre>
<div class="block">Print this MultiLayerFeedForwardNeuralNetwork to stdout.
 All we print the weights of each unit in each non-input layer in
 tab-separated format: LAYERNUM UNITNUM w_0 w_1 ... w_n.</div>
</li>
</ul>
<a name="getOutputValue--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOutputValue</h4>
<pre>public&nbsp;int&nbsp;getOutputValue()</pre>
<div class="block">Output of a MultiLayerFeedForwardNeuralNetwork is the index of output unit
 (i.e., class label) with the maximum activation.
 You could override this in a subclass if you wanted something different.</div>
</li>
</ul>
<a name="train-java.util.List-int-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>train</h4>
<pre>public&nbsp;void&nbsp;train(java.util.List&lt;<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&gt;&nbsp;examples,
                  int&nbsp;epochs,
                  double&nbsp;alpha)</pre>
<div class="block">AIMA BACK-PROP-LEARNING algorithm (Fig 18.24).</div>
</li>
</ul>
<a name="initializeWeights--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeWeights</h4>
<pre>public&nbsp;void&nbsp;initializeWeights()</pre>
<div class="block">AIMA Fig 18.24 says weights should each be initialized to
 ``a small random number.'' WTF? It also has that step inside
 the learning loop, which strikes me as very wrong.
 For now I'm setting all non-input unit weights to w in range [-0.05,0.05].</div>
</li>
</ul>
<a name="train-nn.core.Example-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>train</h4>
<pre>public&nbsp;void&nbsp;train(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example,
                  double&nbsp;alpha)</pre>
<div class="block">AIMA Fig 18.14 body of loop looks like three steps, but it's really four:
 (1) ``Propagate the inputs forward to compute the outputs''
 (2) Computing the error vector delta
 (3) ``Propagating deltas backward from output layer to input layer''
 (4) ``Update every weight in network using deltas''</div>
</li>
</ul>
<a name="propagate-nn.core.Example-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>propagate</h4>
<pre>public&nbsp;void&nbsp;propagate(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example)</pre>
<div class="block">AIMA Fig 18.14: Body of main loop, step 1:
 ``Propagate the inputs forward to compute the outputs.''</div>
</li>
</ul>
<a name="backprop-nn.core.Example-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backprop</h4>
<pre>public&nbsp;void&nbsp;backprop(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example,
                     double&nbsp;alpha)</pre>
<div class="block">AIMA Fig 18.14 body of loop after propagating inputs forward:
 (2) Computing the error vector delta
 (3) ``Propagating deltas backward from output layer to input layer''
 (4) ``Update every weight in network using deltas''</div>
</li>
</ul>
<a name="test-nn.core.Example-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>test</h4>
<pre>public&nbsp;boolean&nbsp;test(<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&nbsp;example)</pre>
<div class="block">Return true if this MultiLayerFeedForwardNeuralNetwork gets the right answer
 on the given Example.
 ``Getting the right answer'' depends on how the problem is represented in the
 network. This default implementation assumes that there is one output unit per
 class label (that is, a vector output). In the Example, only one of these will
 be 1.0 and the others will be 0.0. This method tests that the index of the output
 unit with the highest activation (the network's ``output'') is the index of the
 1.0 in the Example's outputs.
 Other things are possible, in which case subclasses can override
 this implementation.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../nn/core/NeuralNetwork.html#test-nn.core.Example-">test</a></code>&nbsp;in class&nbsp;<code><a href="../../nn/core/NeuralNetwork.html" title="class in nn.core">NeuralNetwork</a></code></dd>
</dl>
</li>
</ul>
<a name="kFoldCrossValidate-java.util.List-int-int-double-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>kFoldCrossValidate</h4>
<pre>public&nbsp;double&nbsp;kFoldCrossValidate(java.util.List&lt;<a href="../../nn/core/Example.html" title="class in nn.core">Example</a>&gt;&nbsp;examples,
                                 int&nbsp;k,
                                 int&nbsp;epochs,
                                 double&nbsp;alpha)</pre>
<div class="block">Run a k-fold cross-validation experiment on this MultiLayerFeedForwardNeuralNetwork using
 the given Examples and return the average accuracy over the k trials.
 For this type of NeuralNetwork, we use a closure to pass the number of epochs and learning
 rate alpha into the training procedure.</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../nn/core/LogisticUnit.html" title="class in nn.core"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../nn/core/NeuralNetwork.html" title="class in nn.core"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../index.html?nn/core/MultiLayerFeedForwardNeuralNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerFeedForwardNeuralNetwork.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested.classes.inherited.from.class.nn.core.NeuralNetwork">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
